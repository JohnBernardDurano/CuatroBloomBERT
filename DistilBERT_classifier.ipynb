{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# DistilBERT Classifier\n",
    "\n",
    "DistilBERT is a lighter transformer model of the original BERT model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Processing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from transformers import DistilBertTokenizer\n",
    "from transformers import TFDistilBertForSequenceClassification"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "p3XKPGzZL9FH"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('blooms_combined_data.csv')\n",
    "\n",
    "# removes all punctuations and change to lower case\n",
    "df['Text'] = df['Text'].str.replace(r'[^\\w\\s]+', '', regex=True)\n",
    "df['Text'] = df['Text'].str.lower()\n",
    "\n",
    "# encode categories into numbers\n",
    "# Analyse - 0\n",
    "# Apply - 1\n",
    "# Create - 2\n",
    "# Evaluate - 3\n",
    "# Remember - 4\n",
    "# Understand - 5\n",
    "\n",
    "df['Label'] = pd.factorize(df.Label)[0]\n",
    "\n",
    "# Blooms taxonomy categories\n",
    "categories = ['Analyse', 'Apply', 'Create', 'Evaluate', 'Remember', 'Understand']"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "vTmZTLDoL9FJ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['Label'].value_counts()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ua8F-SHKL9FK",
    "outputId": "769fe15a-c581-403b-dfb3-bd504efafbfb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split into Train and Validation data\n",
    "train, val = train_test_split(df, test_size=0.2, random_state=0)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "i_9kYU5bL9FK"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train['Label'].value_counts()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5wkBebcTL9FL",
    "outputId": "ab41515b-9e24-42d9-dfa4-7a7177b2cfb6"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NLPAug to augment text data for Oversampling (Optional)\n",
    "\n",
    "For this model, this is **not used** as it generates too much noise"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.word as nlpaw\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def augment_sentence(sentence, aug):\n",
    "    \"\"\"\"\"\"\"\"\"\n",
    "    Constructs a new sentence via text augmentation.\n",
    "\n",
    "    Input:\n",
    "        - sentence:     A string of text\n",
    "        - aug:          An augmentation object defined by the nlpaug library\n",
    "\n",
    "    Output:\n",
    "        - A string of text that been augmented\n",
    "    \"\"\"\"\"\"\"\"\"\n",
    "    return aug.augment(sentence)[0]\n",
    "    \n",
    "\n",
    "\n",
    "def augment_data(df, aug, target_count):\n",
    "    \"\"\"\"\"\"\"\"\"\n",
    "    Takes a pandas DataFrame and augments its text data to a target count\n",
    "    \n",
    "    Input:\n",
    "        - df:            A pandas DataFrame\n",
    "        - aug:           Augmentation object defined by the nlpaug library.\n",
    "        - target_count:  Integer representing the number of times to augment text to match count\n",
    "    Output:\n",
    "        - df:            Copy of the same pandas DataFrame with augmented data \n",
    "                         appended to it and with rows randomly shuffled.\n",
    "    \"\"\"\"\"\"\"\"\"\n",
    "    for category in tqdm(df['Label'].unique()):\n",
    "        # gets the existing data\n",
    "        existing_text = df[df['Label']==category]\n",
    "\n",
    "        # number of extra augmented data to be generated\n",
    "        num_to_gen = target_count - len(existing_text)\n",
    "\n",
    "        # do not need to generate more as target count has been obtained\n",
    "        if num_to_gen <= 0:\n",
    "            continue\n",
    "\n",
    "        # randomly select required number of text from current sample\n",
    "        data_to_aug = existing_text.sample(n=num_to_gen, replace=True)\n",
    "\n",
    "        # augment the data\n",
    "        data_to_aug['Text'] = data_to_aug['Text'].apply(augment_sentence, aug=aug)\n",
    "\n",
    "        df = df.append(data_to_aug, ignore_index=True)\n",
    "    \n",
    "    # shuffle samples and return\n",
    "    return df.sample(frac=1, random_state=0)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "VFfmoEx4L9FL"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Use wordnet to replace words with synonyms\n",
    "aug = nlpaw.SynonymAug(aug_src='wordnet',aug_max=3)\n",
    "\n",
    "# get label with the highest count from training set\n",
    "max_count = max(list(train['Label'].value_counts()))\n",
    "\n",
    "# augment all training datasets to max_count\n",
    "# balanced__train = augment_data(train, aug, target_count=max_count)\n",
    "\n",
    "# skip augmenting step\n",
    "balanced__train = train"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "pn9wtVh6L9FM"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "balanced__train['Label'].value_counts()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "APU_MxxeL9FM",
    "outputId": "97d1c301-14db-4dc9-8682-f96832948cf0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tokenizing data into BERT input format"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_texts = list(balanced__train['Text'])\n",
    "train_labels = list(balanced__train['Label'])\n",
    "\n",
    "val_texts = list(val['Text'])\n",
    "val_labels = list(val['Label'])\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "OdjXVwPDL9FN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    "))\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    val_labels\n",
    "))"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "30FyzyzZL9FN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Building"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Model Params\n",
    "\n",
    "LEARNING_RATE = 0.000001\n",
    "BATCH_SIZE = 24\n",
    "EPOCHS = 50"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "UxByQcC6L9FN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=6)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=model.hf_compute_loss, metrics=['accuracy'])"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "y3i9ULrUL9FN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(train_dataset.batch(BATCH_SIZE), epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "          validation_data=val_dataset.batch(BATCH_SIZE), shuffle=True, callbacks=[callback])\n",
    "\n",
    "# EPOCH 40: loss: 0.0773 - accuracy: 0.9820 - val_loss: 0.3031 - val_accuracy: 0.9109"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sG82zXfcL9FO",
    "outputId": "2a198e89-689f-4856-ccfb-89b4f2aacb41"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_train = history.history['accuracy']\n",
    "loss_val = history.history['val_accuracy']\n",
    "epochs = range(1, EPOCHS + 1)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training accuracy')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "zEYO7JoNL9FO",
    "outputId": "1a56d8ed-15bc-4ccb-e76d-deeff24dbc49"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_train = history.history['loss']\n",
    "loss_val = history.history['val_loss']\n",
    "epochs = range(1,EPOCHS + 1)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "IdemtsCSL9FO",
    "outputId": "5daa5e11-9efa-4900-d8ee-2b8afed4d9e3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_directory = \"saved_models\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save_pretrained(save_directory)\n",
    "tokenizer.save_pretrained(save_directory)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J8YUFhJQL9FO",
    "outputId": "27520b8a-9815-44a4-f50b-247404a6cd40"
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "HIT7gtzOPmbg",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "load_directory = \"BloomBERT_model\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loaded_tokenizer = DistilBertTokenizer.from_pretrained(load_directory)\n",
    "loaded_model = TFDistilBertForSequenceClassification.from_pretrained(load_directory)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "09Wx3FNXL9FO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing Predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "category_dict = {0: 'Analyse', 1: 'Apply', 2: 'Create', 3: 'Evaluate', 4: 'Remember', 5: 'Understand'}"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "IoJ1UaARL9FP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def predict_blooms(text):\n",
    "    predict_input = loaded_tokenizer.encode(text,\n",
    "                                     truncation=True,\n",
    "                                     padding=True,\n",
    "                                     return_tensors=\"tf\")\n",
    "\n",
    "    output = loaded_model(predict_input)[0]\n",
    "\n",
    "    prediction_value = tf.argmax(output, axis=1).numpy()[0]\n",
    "\n",
    "    return category_dict[prediction_value]"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "_RJAKd8gL9FP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remember talking points of a meeting\n",
      "Predicted Class: Remember\n"
     ]
    }
   ],
   "source": [
    "test_text = \"remember talking points of a meeting\"\n",
    "\n",
    "print(test_text)\n",
    "print(\"Predicted Class:\", predict_blooms(test_text))"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zn6TjOPgL9FP",
    "outputId": "47539272-8175-4759-a059-64cd9fb2494a"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Report"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_report = pd.read_csv('sample_data.csv')\n",
    "\n",
    "# removes all punctuations and change to lower case\n",
    "test_report['Text'] = test_report['Text'].str.replace(r'[^\\w\\s]+', '', regex=True)\n",
    "test_report['Text'] = test_report['Text'].str.lower()\n",
    "\n",
    "# encode categories into numbers\n",
    "# test_report['Label'] = pd.factorize(test_report.Label)[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_report"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# for loading bar\n",
    "tqdm.pandas()\n",
    "\n",
    "# predict labels on validation\n",
    "test_report['Predictions'] = test_report['Text'].progress_apply(predict_blooms)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_report"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}